{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Chapter 6 - Learn How to Prepare Data with Scikit-learn.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyOyViUN9m3AAdQyXU2wN+Ko"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"zRd94xEVA8fX"},"source":["# Develop Deep Learning Models for Natural Language in Python"]},{"cell_type":"markdown","metadata":{"id":"8kNFCUxcA6j_"},"source":["## Chapter 6 - Learn How to Prepare Data with Scikit-learn"]},{"cell_type":"markdown","metadata":{"id":"96mg4gtEPEDx"},"source":["### 6.2 - Word Counts with CountVectorizer"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZIpd8Z6nA7Ct","executionInfo":{"status":"ok","timestamp":1625901774202,"user_tz":-270,"elapsed":3,"user":{"displayName":"Keivan Ipchi Hagh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg86N33hQca1Ab2Qwir_Bu36nKxiHcT9Q3omHQcsA=s64","userId":"02569620274590613261"}},"outputId":"d101cb1c-6d59-4e2c-af97-3e94638a5c76"},"source":["from sklearn.feature_extraction.text import CountVectorizer\n","\n","text = ['The quick brown fox jumed over the lazy dog.']\n","\n","# Create a transform\n","vectorizer = CountVectorizer()\n","\n","# Fit & transform the text\n","vector = vectorizer.fit_transform(text)\n","\n","print('Vocabulary:', vectorizer.vocabulary_)\n","print('Vector shape:', vector.shape)\n","print('Array:', vector.toarray())"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Vocabulary: {'the': 7, 'quick': 6, 'brown': 0, 'fox': 2, 'jumed': 3, 'over': 5, 'lazy': 4, 'dog': 1}\n","Vector shape: (1, 8)\n","Array: [[1 1 1 1 1 1 1 2]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"VvuB-ReURz9F"},"source":["### 6.3 - Word Frequencies with tfidfVectorizer"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gngJb_1cQIej","executionInfo":{"status":"ok","timestamp":1625901853745,"user_tz":-270,"elapsed":371,"user":{"displayName":"Keivan Ipchi Hagh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg86N33hQca1Ab2Qwir_Bu36nKxiHcT9Q3omHQcsA=s64","userId":"02569620274590613261"}},"outputId":"d826ff07-316e-4c99-9822-10adaa22735b"},"source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","text = ['The quick brown fox jumed over the lazy dog.', 'The dog', 'The fox']\n","\n","# Create the transform\n","vectorizer = TfidfVectorizer()\n","\n","vector = vectorizer.fit_transform(text)\n","\n","print('Vocabulary:', vectorizer.vocabulary_)\n","print('Vector shape:', vector.shape)\n","print('Array:', vector.toarray())"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Vocabulary: {'the': 7, 'quick': 6, 'brown': 0, 'fox': 2, 'jumed': 3, 'over': 5, 'lazy': 4, 'dog': 1}\n","Vector shape: (3, 8)\n","Array: [[0.36388646 0.27674503 0.27674503 0.36388646 0.36388646 0.36388646\n","  0.36388646 0.42983441]\n"," [0.         0.78980693 0.         0.         0.         0.\n","  0.         0.61335554]\n"," [0.         0.         0.78980693 0.         0.         0.\n","  0.         0.61335554]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"gdHJkXuDfY2a"},"source":["### 6.4 - Hashing with HashingVectorizer"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cPHTWUXqTDXQ","executionInfo":{"status":"ok","timestamp":1625905135085,"user_tz":-270,"elapsed":496,"user":{"displayName":"Keivan Ipchi Hagh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg86N33hQca1Ab2Qwir_Bu36nKxiHcT9Q3omHQcsA=s64","userId":"02569620274590613261"}},"outputId":"d3d5a005-72c9-4178-92ac-980032868584"},"source":["from sklearn.feature_extraction.text import HashingVectorizer\n","\n","text = ['The quick brown fox jumed over the lazy dog.']\n","\n","# Create the transform\n","vectorizer = HashingVectorizer(n_features = 20)\n","\n","vector = vectorizer.fit_transform(text)\n","\n","print('Vector shape:', vector.shape)\n","print('Array:', vector.toarray())"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Vector shape: (1, 20)\n","Array: [[ 0.          0.          0.          0.          0.30151134  0.30151134\n","   0.         -0.30151134  0.30151134  0.          0.          0.30151134\n","   0.         -0.30151134  0.         -0.30151134  0.          0.\n","  -0.60302269  0.        ]]\n"],"name":"stdout"}]}]}